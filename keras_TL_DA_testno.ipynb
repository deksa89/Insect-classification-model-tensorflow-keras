{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import  Sequential, Model\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from classification_models.tfkeras import Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_available = tf.config.list_physical_devices('GPU')\n",
    "gpu_available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_train = \"keras_insect_splited/train\"\n",
    "directory_val = \"keras_insect_splited/val\"\n",
    "directory_test = \"keras_insect_splited/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "\n",
    "HORIZONTAL_FLIP=True\n",
    "VERTICAL_FLIP=True\n",
    "# ROTATION_RANGE=40\n",
    "# WIDTH_SHIFT_RANGE=0.2\n",
    "# HEIGHT_SHIFT_RANGE=0.2\n",
    "# SHEAR_RANGE=0.2\n",
    "# ZOOM_RANGE=0.1\n",
    "# BRIGHTNESS_RANGE=[0.8,1.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageDataGenerator accepts file types: 'png', 'jpg', 'jpeg', 'bmp', 'ppm', 'tif', 'tiff'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    horizontal_flip=HORIZONTAL_FLIP,\n",
    "    vertical_flip=VERTICAL_FLIP,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory_train,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\", ## \"categorical\" will be 2D one-hot encoded labels\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        directory_val,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory_test,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=1116\n",
    "    #shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = next(os.walk(directory_train))[1]\n",
    "target_labels.sort()\n",
    "print(target_labels)\n",
    "\n",
    "num_classes = len(target_labels)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(train_generator)\n",
    "batch_images = np.array(batch[0])\n",
    "batch_labels = np.array(batch[1])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "for n, i in enumerate(np.arange(6)):\n",
    "    ax = plt.subplot(3,3,n+1)\n",
    "    plt.imshow(batch_images[i])\n",
    "    plt.title(target_labels[np.argmax(batch_labels[i])])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. CREATING A NEW TRAINING MODEL OR USING PRETRAINED MODEL???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "model = ResNet18((IMG_SIZE, IMG_SIZE, 3), weights='imagenet')\n",
    "\n",
    "base_model = model\n",
    "#base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet18(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=[base_model.input], outputs=[output])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model_imported.layers[:-3]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# for l in model_imported.layers:\n",
    "#     print(l.name, \" - \", l.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_weights(model):\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = pretrained_weights(model)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', min_delta=0.001, verbose=1, patience=6),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=15, min_lr=1e-20, verbose=1, cooldown=3),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=\"saved_models/best_model.h5\", monitor='val_accuracy', mode='max', save_best_only=True, save_weights_only=True)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_gen, valid_gen, epochs):\n",
    "    train_steps_per_epoch = train_gen.n // train_gen.batch_size\n",
    "    valid_steps_per_epoch = valid_gen.n // valid_gen.batch_size\n",
    "\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=train_steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        validation_steps=valid_steps_per_epoch,\n",
    "        callbacks=my_callbacks,\n",
    "        validation_data=valid_gen\n",
    "    )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_frozen_model = train_model(new_model, train_generator, validation_generator, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(history_frozen_model.history['accuracy'])\n",
    "plt.plot(history_frozen_model.history['val_accuracy'])\n",
    "plt.title('Accuracy vs. epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history_frozen_model.history['loss'])\n",
    "plt.plot(history_frozen_model.history['val_loss'])\n",
    "plt.title('Loss vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "loaded_model = keras.models.load_model(\"saved_models/best_model.pb\")\n",
    "#loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_test_loss, new_model_test_acc = loaded_model.evaluate(test_generator)\n",
    "\n",
    "print('\\nTest dataset')\n",
    "print(f\"Loss: {new_model_test_loss}\")\n",
    "print(f\"Accuracy: {new_model_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(test_generator)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(images[i])\n",
    "\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i])\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = loaded_model.predict(img_array)\n",
    "    \n",
    "    predicted_class = target_labels[np.argmax(predictions[0])]\n",
    "\n",
    "    confidence = round(100*(np.max(predictions[0])), 2)\n",
    "\n",
    "    actual_class = target_labels[np.argmax(labels[i])]\n",
    "    \n",
    "\n",
    "    plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class},\\n Confidence: {confidence}\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_lista = []\n",
    "y_pred_lista = []\n",
    "\n",
    "images, labels = next(test_generator)\n",
    "print(len(images))\n",
    "\n",
    "for i in range(len(images)):\n",
    "\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i])\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = loaded_model.predict(img_array)\n",
    "\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    y_pred_lista.append(predicted_class)\n",
    "\n",
    "    actual_class = np.argmax(labels[i])\n",
    "    actual_class = actual_class\n",
    "    y_true_lista.append(actual_class)\n",
    "\n",
    "# print(\"y_true_lista: \", y_true_lista)\n",
    "# print(\"y_pred_lista: \", y_pred_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true_lista, y_pred_lista)\n",
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in target_labels],\n",
    "                     columns = [i for i in target_labels])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "\n",
    "np_image = Image.open(\"frame2190.jpg\")\n",
    "np_image = np.array(np_image).astype('float32')/255\n",
    "\n",
    "np_image = transform.resize(np_image, (224, 224, 3))\n",
    "np_image = np.expand_dims(np_image, axis=0)\n",
    "\n",
    "prediction = loaded_model.predict(np_image)\n",
    "predicted_name = target_labels[np.argmax(prediction[0])]\n",
    "predicted_name"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5fa8dcf83f4ee99e2a084d76cadd7b861c415c77711d8f908fcbcbf8986101cd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('keras-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
